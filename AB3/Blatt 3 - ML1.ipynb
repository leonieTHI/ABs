{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header\"\n",
    "\n",
    "<p style=\"text-align: left;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "    <span style=\"float: left\">\n",
    "     Technische Hochschule Ingolstadt<br>\n",
    "     Prof. Dr. Sören Gröttrup\n",
    "    </span>\n",
    "    <span style=\"float: right;\">\n",
    "       Machine Learning 1<br>\n",
    "        <span style=\"float: right;\">WS 23/24</span>\n",
    "    </span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header Aufgabenblatt\"\n",
    "<br>\n",
    "<p style=\"text-align: center;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "     <span style=\"font-weight: bold;\">Aufgabenblatt 3</span><br>\n",
    "     Themen: Cross-Validation, Overfitting, Normalisierung, Einführung in PyTorch<br>\n",
    "     Abgabetermin: 26.11.23, 23:59 Uhr <br>\n",
    "     Punkte: 32 (+4)\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Namen:** _Bitte tragen Sie hier die Namen der Abgabegruppe ein._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. K-fold Cross-Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Funktionen in sklearn \n",
    "Python stellt einige Funktionen für die Cross-Validation zur Verfügung, welche in der Bibliothek `sklearn.model_selection` zu finden sind. Insbesondere die folgenden Funktionen sind dabei hilfreich:\n",
    "\n",
    "1. `KFold`\n",
    "1. `cross_validate`\n",
    "1. `cross_val_score`\n",
    "\n",
    "Genaue Informationen finden Sie auf der Seite https://scikit-learn.org. Einige Funktionen geben einen Evaluationsscore zurück. Schauen Sie auch nach, wie Sie den Standard-Rückgabe-Score ändern können, z.B. in den RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten\n",
    "Der Datensatz `Ozone.csv` enthält meterologische Daten und die Konzentration von Ozone (O3) in der Luft im Raum Los Angeles. Die folgende Tabelle zeigt die Beschreibung der Variablen.\n",
    "\n",
    "|Name of variable| Description|\n",
    "| --- | --- |\n",
    "|O3| Daily maximum of the hourly average ozone concentration|\n",
    "|Vh| 500 millibar pressure height|\n",
    "|Wind| Wind speed in mph|\n",
    "|Humidity| Humidity in percent|\n",
    "|Temp| Temperature in degrees Fahrenheit|\n",
    "|Ibh| Temperature inversion base height in feet|\n",
    "|Dpg| Pressure gradient in mm Hg|\n",
    "|Ibt| Inversion base temperature in degrees Fahrenheit|\n",
    "|Vis| Visibility|\n",
    "|Day| Day of year|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Daten laden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"./Daten Blatt 3/Ozone.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Featur-Matrix and Target Variable\n",
    "X = data.drop(columns=(\"O3\"))\n",
    "y = data[\"O3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1.1 (Lineare Regression mittels K-fold X-Validation) [10 Punkte]\n",
    "1.  Führen Sie folgenden Code aus. Beschreiben Sie was die einzelnen Zeilen Code machen und deren Ergebnis. _Hinweis:_ Ermitteln Sie die Dimension von `X_train`, `X_test`, etc.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "```\n",
    "\n",
    "2. Trainieren Sie ein lineares Regressionsmodell auf den in 1. generierten Trainignsdaten. Berechnen Sie dann den RMSE für den Trainings und Testdatensatz.\n",
    "2. Erstellen Sie nun ein lineares Regressionsmodell mittels 10-facher Kreuzvalidierung, was aus den meterologischen Daten die Ozone-Konzentration in der Luft schätzt. Sie können dafür die oben angegebenen Funktionen `KFold`, `cross_validate` oder `cross_val_score` nutzen. Verwenden Sie als Gütemaß den _Root Mean Squared Error (RMSE)_.\n",
    "2. Was ist der RMSE für das in 3. trainierte Modell auf dem Trainings- und auf dem Testdatensatz? Und vergleichen Sie das Ergebnis mit dem RMSE aus Teil 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lösung Aufgabe 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1.2 (Finden des optimalen k im kNN) [10 Punkte]\n",
    "Ziel der Aufgabe ist die Erstellung eines kNN-Regressionsmodells, welches die O3-Konzentration auf Basis der anderen Variablen vorhersagt. Für die Wahl des \"besten\" Modells müssen Sie den optimalen Hyperparameter `k` bestimmen, welcher die Anzahl an Nachbarn im kNN-Modell angibt. In dieser Aufgabe sollen Sie für die Bestimmung das Cross-Validation Verfahren anwenden.\n",
    "\n",
    "1. Splitten Sie 20% des Datensatzen als Validierungsdaten ab. Benutzen Sie dafür die Funktion `train_test_split` mit `random_state = 123`. \n",
    "1. Trainieren Sie auf den restlichen Daten für jedes $k=1,...,50$ ein k-Nearest Neigbor Modelle mittels 10-facher Kreuzvalidierung.\n",
    "1. Visualisieren Sie den RMSE für die Trainingsdaten und Testdaten innerhalb der Kreuzvalidierung. Für welche $k$ tritt Overfitting ein?\n",
    "1. Für welches $k$ zeigt das kNN Modell die beste Güte bezogen auf den RMSE? \n",
    "1. Erstellen Sie ein finales Modell, indem Sie für das gefundene $k$ ein kNN auf den ganzen Trainingsdaten erzeugen.\n",
    "1. Validieren Sie das Modell auf den Validierungsdaten. Ist das gefundene Modell geeignet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lösung Aufgabe 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1.3  [10 Punkte]\n",
    "1. Betrachten Sie den `Ozone` Datensatz. Was für ein Problem könnte hier beim Training eines Modells auftreten? \n",
    "1. Informieren Sie sich über die Funktion `StandardScaler()` im Paket `sklearn.preprocessing`. Welche Transformation der Features führt diese aus? \n",
    "1. Führen Sie wie in der Aufgabe davor eine 10-fache kreuzvalidierung durch, zur Bestimmung des optimalen $k=1,...,50$ für ein k-Nearest Neighbor Modell, jedoch für skalierte Feature. Sie können dabei den gleichen Validierungsdatensatz wie in der vorherigen Aufgabe verwenden. Berechnen Sie auch hier jeweils den RMSE. Welches $k$ ist in diesem Fall optimal?\n",
    "1. Trainieren Sie wieder ein finales Modell auf allen Trainignsdaten für das von Ihnen gefundenen optimale $k$ und validieren Sie dieses auf dem Validierungsdatensatz. Vergleichen Sie das Ergebnis mit dem aus der vorherigen Aufgabe.\n",
    "\n",
    "_Hinweise:_ \n",
    "* Achten Sie darauf, dass Sie bei der Erstellung der Modelle in der Kreuzvalidierung Training und Test sauber trennen. Dies gilt auch insbesondere für die Skalierung! \n",
    "* Machen Sie sich also Gedanken über die Reihenfolde der einzelnen Schritte, bevor Sie den Algorithmus implementieren.\n",
    "* Die Funktion `Pipeline` in `sklearn.pipeline` kann hier sehr nützlich sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Lösung Aufgabe 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bootstrapverfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2.1 [2 Punkte]\n",
    "\n",
    "Sei $B$ die Anzahl an Bootstrap Datensätzen. In der Vorlesung wurde gesagt, dass sich für großes $B$ das Bootstrap-Verfahren so verhält wie eine Leave-one-out CV. Geben Sie dafür eine Begründung an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antwort zu Aufgabe 2.1\n",
    "Der größte Unterschied zwischen Bootstrap Verfahren und LOO CV ist, dass beim Bootrstrap Verfahren ein \"Ziehen mit Zurücklegen\" stattfindet, also theoretisch auch zufällig zwei völlig identische Trainingsdatensätze entstehen könnten.Bei einem sehr großen B spielt dieser Zufall allerdings keine Rolle mehr im Verhältnis, da der Fall identischer Datensätze oder doppelter Datenpunkte in einem Trainingsdatensatz B eher gering auftritt. Die Testdatensätze unterscheiden sich dadurch strukturell kaum und der berechnete Error nährt sich einander an. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Einführung in  Pytorch\n",
    "\n",
    "In den nächsten Aufgabenblättern werden wir PyTorch verwenden, um Neuronale Netze zu trainieren. Dieser Abschnitt dient dazu sich selbstständig mit PyTorch vertraut zu machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Aufgabe 3.1 [0 Punkte]\n",
    "\n",
    "Beschäftigen Sie sich mit Pytorch, in dem Sie z.B. einige der folgenden Tutorien durchspielen.\n",
    "\n",
    "**Tutorien:**\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "\n",
    "* https://cs230.stanford.edu/blog/pytorch/\n",
    "\n",
    "* https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3.2 [0 Punkte]\n",
    "\n",
    "Im unten liegenden Code wird eine Lineare Regression auf dem Datensatz `Ozone` zur Vorhersage von `O3` in PyTorch trainiert. Schauen Sie sich den Code an und versuchen Sie die einzelnen Schritte nachzuvollziehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load Packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as net\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Variables (StandardScaler)\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fit & transform scaler\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "# apply scaler to test set\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Tensor\n",
    "x_train_ts = torch.tensor(X_train, dtype=torch.float)\n",
    "x_test_ts = torch.tensor(X_test, dtype=torch.float)\n",
    "\n",
    "y_train_ts = torch.tensor(y_train.to_numpy(), dtype=torch.float).view(-1,1)\n",
    "y_test_ts = torch.tensor(y_test.to_numpy(), dtype=torch.float).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ts.shape, y_train_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Hyper-Parameter, Model and Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyper-Parameters\n",
    "n_iterations = 40\n",
    "learning_rate = 0.05\n",
    "\n",
    "random_seed = 12\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the linear regression model\n",
    "class LinReg(net.Module):\n",
    "    def __init__(self):\n",
    "        super(LinReg, self).__init__()\n",
    "        self.linear = net.Linear(9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Linear Regression & Optimizer (Gradient Descent)\n",
    "linear_regression = LinReg()\n",
    "optimizer = optim.SGD(linear_regression.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable to save the loss for each iteration\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Trainin\n",
    "# Performe Parameter-Update in every Iteration via Gradient Descent\n",
    "\n",
    "for epoch in range(1, n_iterations + 1):\n",
    "    \n",
    "    # --- Training ----#\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = linear_regression(x_train_ts)\n",
    "    train_loss = F.mse_loss(y_pred, y_train_ts)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "     \n",
    "    \n",
    "    # ----- Evaluation metrics train ---- #\n",
    "    train_losses.append(np.sqrt(train_loss.item()))\n",
    "    \n",
    "    # ----- Test Prediction & Evaluation -------------#\n",
    "    y_test_pred = linear_regression(x_test_ts)\n",
    "    \n",
    "    # Loss\n",
    "    test_loss = F.mse_loss(y_test_pred, y_test_ts)\n",
    "    test_losses.append(np.sqrt(test_loss.item()))\n",
    "    \n",
    "    # Print Validation criteria\n",
    "    print(f'''Iteration {epoch}, Train set - loss: {round(np.sqrt(train_loss.item()), 3)} | Test set - Loss: {round(np.sqrt(test_loss.item()), 3)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Training Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training process\n",
    "plt.plot(train_losses, label=\"Training\")\n",
    "plt.plot(test_losses, c='blue', label=\"Test\")\n",
    "plt.title(\"RMSE-Loss of Training\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aufgabe 3.2 (Zusatzaufgabe) (Logistische Regression in PyTorch) [4 Punkte*]\n",
    "**Diese Punkte sind nicht relevant für die Bestimmung der Bestehensgrenze, können aber von Ihnen als Zusatzpunkte gesammelt werden.**\n",
    "\n",
    "Der _Wisconsin Breast Cancer_ Datensatz enthält Messwerte von Gewebeproben der Brust, sowie eine Variable `diagnosis`, welche angibt, ob die Gewebeprobe tumorös (1) oder gesund ist (0). Weitere Informationen finden Sie hier: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "\n",
    "Schreiben Sie den obigen Code um, so dass Sie eine logistische Regression trainieren, welche basierend auf den Messwerten erkennt, ob eine vorliegnde Gewebeprobe tumorös oder nicht-tumorös ist. Benutzen Sie als Verlustfunktion die Cross-Entropy. Was ist die Accuracy auf den Trainingsdaten? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lösung Aufgabe 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_dataset = load_breast_cancer()\n",
    "cancer = pd.DataFrame(cancer_dataset.data, columns=cancer_dataset.feature_names)\n",
    "cancer[\"diagnosis\"] = cancer_dataset.target\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_dataset.data, cancer_dataset.target, test_size = 0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Variables (StandardScaler)\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fit & transform scaler\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "# apply scaler to test set\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Tensor\n",
    "x_train_ts = torch.tensor(X_train, dtype=torch.float)\n",
    "x_test_ts = torch.tensor(X_test, dtype=torch.float)\n",
    "\n",
    "y_train_ts = torch.tensor(y_train, dtype=torch.long).view(-1,1)\n",
    "y_test_ts = torch.tensor(y_test, dtype=torch.long).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ts.shape, y_train_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ihr Code ab hier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
